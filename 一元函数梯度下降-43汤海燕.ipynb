{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a431c4d3-364a-4940-ad65-0edb8e820b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b49770f-9da1-4b13-8ad0-6573f4e96d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = \"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a83cd1-b8e6-47ec-84cd-89917496ec16",
   "metadata": {},
   "source": [
    "使用梯度下降算法找到一元二次函数的最小值点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a1854c-80fd-4ac2-a9b5-f53eae37c0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0:  tensor(0.0121, requires_grad=True) y0:  tensor(0.0001, grad_fn=<PowBackward0>) x0.grad:  tensor(0.0242)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x0 = torch.tensor(5.0, requires_grad=True)\n",
    "y0 = x0**2\n",
    "\n",
    "alpha = 0.1\n",
    "epsilon = 0.0001\n",
    "\n",
    "x_values = []\n",
    "y_values = []\n",
    "\n",
    "# 循环直到y的变化小于epsilon\n",
    "while True:\n",
    "    # 计算梯度\n",
    "    y0.backward()\n",
    "    y = y0.item()  # 保存y0在当前迭代的取值，用于判断迭代的停止条件\n",
    "    # 更新x0\n",
    "    with torch.no_grad():\n",
    "        x0 -= alpha * x0.grad  # x0 = x0-alpha * x0.grad 创建一个新的张量并赋值给x\n",
    "    x0.grad.zero_()\n",
    "    # 计算新的y0\n",
    "    y0 = x0**2\n",
    "    # 检查是否满足结束条件\n",
    "    if abs(y0.item() - y) < epsilon:\n",
    "        break\n",
    "\n",
    "y0.backward()\n",
    "print(\"x0: \", x0, \"y0: \", y0, \"x0.grad: \", x0.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866f1aad-2e1e-4b9b-b841-46662bcb954d",
   "metadata": {},
   "source": [
    "一元函数梯度下降算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61c7d70f-8847-442a-9a0d-a464b3ccb73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全局最小值的近似解为 x = 2.082414942088666, y = 3.921260749602342\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    " \n",
    "# 定义一元函数，具有两个波谷\n",
    "def f(x):\n",
    "    return x**2 + 4*np.sin(2*x) + 3  \n",
    " \n",
    "# 计算梯度（导数）\n",
    "def df(x):\n",
    "    return 2*x + 8*np.cos(2*x)  # f(x)的导数\n",
    " \n",
    "# 梯度下降算法\n",
    "def gradient_descent(starting_point, learning_rate, max_iterations, tol=1e-6):\n",
    "    x = starting_point\n",
    "    for i in range(max_iterations):\n",
    "        grad = df(x)\n",
    "        new_x = x - learning_rate * grad\n",
    "        if abs(new_x - x) < tol:  # 检查收敛性\n",
    "            break\n",
    "        x = new_x\n",
    "    return x\n",
    " \n",
    "# 设置参数\n",
    "starting_point = 5.0  # 初始点\n",
    "learning_rate = 0.1   # 学习率\n",
    "max_iterations = 1000 # 最大迭代次数\n",
    " \n",
    "# 运行梯度下降算法\n",
    "optimal_x = gradient_descent(starting_point, learning_rate, max_iterations)\n",
    "optimal_y = f(optimal_x)\n",
    " \n",
    "# 输出结果\n",
    "print(f\"全局最小值的近似解为 x = {optimal_x}, y = {optimal_y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5492dd-78b3-4d2d-a791-e081857f2b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
